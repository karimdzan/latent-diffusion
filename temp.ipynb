{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from diffusers import AutoencoderKL\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "\n",
    "# Load pre-trained VAE model\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
    "vae.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Function to preprocess an image to 64x64 and convert to tensor\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = Resize((64, 64))  # Resize to 64x64 if necessary\n",
    "    image = transform(image)\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0)\n",
    "    image_tensor = Normalize(mean=[0.5], std=[0.5])(image_tensor)  # Add batch dimension\n",
    "    return image_tensor  # Scale to [-1, 1] for the VAE model\n",
    "\n",
    "# Load and preprocess a 64x64 image\n",
    "# image_path = \"/Users/karim/Downloads/food_data/train/apple_pie/157083.jpg\"\n",
    "rec_images = []\n",
    "real_images = []\n",
    "for cls in os.listdir(\"/Users/karim/Downloads/food_data/test\"):\n",
    "    if os.path.isdir(\"/Users/karim/Downloads/food_data/test/\" + cls):\n",
    "        for image_path in os.listdir(\"/Users/karim/Downloads/food_data/test/\" + cls):\n",
    "            image_tensor = preprocess_image(\"/Users/karim/Downloads/food_data/test/\" + cls + '/' + image_path)\n",
    "\n",
    "        # Encode the image into the latent space\n",
    "            with torch.no_grad():\n",
    "                latent_representation = vae.encode(image_tensor).latent_dist.sample()\n",
    "\n",
    "            # Decode the latent representation back to the image space\n",
    "            with torch.no_grad():\n",
    "                reconstructed_image = vae.decode(latent_representation).sample\n",
    "\n",
    "            # Post-process to display the reconstructed image\n",
    "            reconstructed_image = (reconstructed_image / 2 + 0.5).clamp(0, 1)  # Scale back to [0, 1]\n",
    "            rec_images.append(reconstructed_image)\n",
    "            real_images.append(image_tensor)\n",
    "# reconstructed_image_pil = ToPILImage()(reconstructed_image.squeeze())\n",
    "\n",
    "# # Display or save the result\n",
    "# reconstructed_image_pil.show()  # Display\n",
    "# reconstructed_image_pil.save(\"reconstructed_image.png\")  # Save if desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ = torch.concat(rec_images, dim=0)\n",
    "real_ = torch.concat(real_images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.174748222875905"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import FIDMetric\n",
    "\n",
    "metric = FIDMetric(name=\"test\", device=\"cpu\")\n",
    "\n",
    "metric(rec_, real_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49618860\n"
     ]
    }
   ],
   "source": [
    "from src.model import Unet\n",
    "\n",
    "unet = Unet(\n",
    "    img_size=8,\n",
    "    init_dim=64,\n",
    "    dim_mults=[1, 2, 4, 8],\n",
    "    time_dim=256,\n",
    "    in_channels=4,\n",
    "    out_channels=4,\n",
    "    down_kern=2,\n",
    "    up_scale=2,\n",
    "    resnet_stacks=3,\n",
    "    attn_heads=8,\n",
    "    attn_head_res=64,\n",
    "    self_condition=False,\n",
    "    resnet_grnorm_groups=8,\n",
    "    classes=101\n",
    ")\n",
    "\n",
    "unet.to(\"cpu\")\n",
    "\n",
    "print(sum(p.numel() for p in unet.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (init_conv): Conv2d(4, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (time_mlp): Sequential(\n",
      "    (0): SinusoidalPositionEmbeddings()\n",
      "    (1): Linear(in_features=8, out_features=256, bias=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (downs): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(128, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DownSample(\n",
      "        (down): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(128, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DownSample(\n",
      "        (down): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DownSample(\n",
      "        (down): Sequential(\n",
      "          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Identity()\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (ups): ModuleList(\n",
      "    (0): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 1024, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 1024, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): UpSample(\n",
      "        (up): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(128, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): UpSample(\n",
      "        (up): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(64, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): UpSample(\n",
      "        (up): Sequential(\n",
      "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ModuleList(\n",
      "      (0): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ResnetBlock(\n",
      "        (mlp): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (block1): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (block2): conv_block(\n",
      "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (res_conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): Residual(\n",
      "        (fn): PreNorm(\n",
      "          (fn): LinearAttnBlock(\n",
      "            (to_qkv): Conv2d(128, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "            )\n",
      "          )\n",
      "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (mid_block1): ResnetBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    )\n",
      "    (block1): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (mid_attn): Residual(\n",
      "    (fn): PreNorm(\n",
      "      (fn): AttnBlock(\n",
      "        (to_qkv): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (to_out): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (norm): GroupNorm(1, 1024, eps=1e-05, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (mid_block2): ResnetBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    )\n",
      "    (block1): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Identity()\n",
      "  )\n",
      "  (final_res_block): ResnetBlock(\n",
      "    (mlp): Sequential(\n",
      "      (0): SiLU()\n",
      "      (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "    )\n",
      "    (block1): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (block2): conv_block(\n",
      "      (proj): WeightStandardizedConv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (res_conv): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (final_conv): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (lbl_embeds): Embedding(101, 256)\n",
      ")\n",
      "Loading model weights from: /home/ubuntu/latent-diffusion/saved/testing/checkpoint-epoch150.pth ...\n",
      "test:   0%|                                               | 0/4 [00:00<?, ?it/s]\n",
      "DDIM Sampling:   0%|\u001b[38;2;243;156;18m                                    \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   1%|\u001b[38;2;243;156;18m▎                           \u001b[0m| 1/100 [00:00<01:30,  1.09it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   6%|\u001b[38;2;243;156;18m█▋                          \u001b[0m| 6/100 [00:01<00:19,  4.89it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  11%|\u001b[38;2;243;156;18m██▉                        \u001b[0m| 11/100 [00:01<00:13,  6.73it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  16%|\u001b[38;2;243;156;18m████▎                      \u001b[0m| 16/100 [00:02<00:10,  7.66it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  21%|\u001b[38;2;243;156;18m█████▋                     \u001b[0m| 21/100 [00:03<00:09,  8.31it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  26%|\u001b[38;2;243;156;18m███████                    \u001b[0m| 26/100 [00:03<00:08,  8.75it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  31%|\u001b[38;2;243;156;18m████████▎                  \u001b[0m| 31/100 [00:04<00:07,  8.88it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  36%|\u001b[38;2;243;156;18m█████████▋                 \u001b[0m| 36/100 [00:04<00:07,  9.05it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  41%|\u001b[38;2;243;156;18m███████████                \u001b[0m| 41/100 [00:05<00:06,  9.24it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  46%|\u001b[38;2;243;156;18m████████████▍              \u001b[0m| 46/100 [00:05<00:05,  9.28it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  51%|\u001b[38;2;243;156;18m█████████████▊             \u001b[0m| 51/100 [00:06<00:05,  9.35it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  56%|\u001b[38;2;243;156;18m███████████████            \u001b[0m| 56/100 [00:06<00:04,  9.45it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  61%|\u001b[38;2;243;156;18m████████████████▍          \u001b[0m| 61/100 [00:07<00:04,  9.38it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  66%|\u001b[38;2;243;156;18m█████████████████▊         \u001b[0m| 66/100 [00:07<00:03,  9.47it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  71%|\u001b[38;2;243;156;18m███████████████████▏       \u001b[0m| 71/100 [00:08<00:03,  9.45it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  76%|\u001b[38;2;243;156;18m████████████████████▌      \u001b[0m| 76/100 [00:08<00:02,  9.42it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  81%|\u001b[38;2;243;156;18m█████████████████████▊     \u001b[0m| 81/100 [00:09<00:02,  9.49it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  86%|\u001b[38;2;243;156;18m███████████████████████▏   \u001b[0m| 86/100 [00:09<00:01,  9.54it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  91%|\u001b[38;2;243;156;18m████████████████████████▌  \u001b[0m| 91/100 [00:10<00:00,  9.50it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  96%|\u001b[38;2;243;156;18m█████████████████████████▉ \u001b[0m| 96/100 [00:10<00:00,  9.53it/s]\u001b[0m\u001b[A\n",
      "test:  25%|█████████▊                             | 1/4 [00:22<01:07, 22.51s/it]\u001b[A\n",
      "DDIM Sampling:   0%|\u001b[38;2;243;156;18m                                    \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   1%|\u001b[38;2;243;156;18m▎                           \u001b[0m| 1/100 [00:00<01:27,  1.14it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   6%|\u001b[38;2;243;156;18m█▋                          \u001b[0m| 6/100 [00:01<00:18,  5.04it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  11%|\u001b[38;2;243;156;18m██▉                        \u001b[0m| 11/100 [00:01<00:12,  6.89it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  16%|\u001b[38;2;243;156;18m████▎                      \u001b[0m| 16/100 [00:02<00:10,  7.91it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  21%|\u001b[38;2;243;156;18m█████▋                     \u001b[0m| 21/100 [00:02<00:09,  8.55it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  26%|\u001b[38;2;243;156;18m███████                    \u001b[0m| 26/100 [00:03<00:08,  8.97it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  31%|\u001b[38;2;243;156;18m████████▎                  \u001b[0m| 31/100 [00:03<00:07,  9.24it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  36%|\u001b[38;2;243;156;18m█████████▋                 \u001b[0m| 36/100 [00:04<00:06,  9.42it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  41%|\u001b[38;2;243;156;18m███████████                \u001b[0m| 41/100 [00:04<00:06,  9.55it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  46%|\u001b[38;2;243;156;18m████████████▍              \u001b[0m| 46/100 [00:05<00:05,  9.64it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  51%|\u001b[38;2;243;156;18m█████████████▊             \u001b[0m| 51/100 [00:05<00:05,  9.69it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  56%|\u001b[38;2;243;156;18m███████████████            \u001b[0m| 56/100 [00:06<00:04,  9.73it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  61%|\u001b[38;2;243;156;18m████████████████▍          \u001b[0m| 61/100 [00:07<00:03,  9.76it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  66%|\u001b[38;2;243;156;18m█████████████████▊         \u001b[0m| 66/100 [00:07<00:03,  9.78it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  71%|\u001b[38;2;243;156;18m███████████████████▏       \u001b[0m| 71/100 [00:08<00:02,  9.80it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  76%|\u001b[38;2;243;156;18m████████████████████▌      \u001b[0m| 76/100 [00:08<00:02,  9.81it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  81%|\u001b[38;2;243;156;18m█████████████████████▊     \u001b[0m| 81/100 [00:09<00:01,  9.81it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  86%|\u001b[38;2;243;156;18m███████████████████████▏   \u001b[0m| 86/100 [00:09<00:01,  9.82it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  91%|\u001b[38;2;243;156;18m████████████████████████▌  \u001b[0m| 91/100 [00:10<00:00,  9.82it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  96%|\u001b[38;2;243;156;18m█████████████████████████▉ \u001b[0m| 96/100 [00:10<00:00,  9.82it/s]\u001b[0m\u001b[A\n",
      "test:  50%|███████████████████▌                   | 2/4 [00:41<00:40, 20.15s/it]\u001b[A\n",
      "DDIM Sampling:   0%|\u001b[38;2;243;156;18m                                    \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   1%|\u001b[38;2;243;156;18m▎                           \u001b[0m| 1/100 [00:00<01:23,  1.18it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   6%|\u001b[38;2;243;156;18m█▋                          \u001b[0m| 6/100 [00:01<00:18,  5.17it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  11%|\u001b[38;2;243;156;18m██▉                        \u001b[0m| 11/100 [00:01<00:12,  7.03it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  16%|\u001b[38;2;243;156;18m████▎                      \u001b[0m| 16/100 [00:02<00:10,  8.05it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  21%|\u001b[38;2;243;156;18m█████▋                     \u001b[0m| 21/100 [00:02<00:09,  8.67it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  26%|\u001b[38;2;243;156;18m███████                    \u001b[0m| 26/100 [00:03<00:08,  9.05it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  31%|\u001b[38;2;243;156;18m████████▎                  \u001b[0m| 31/100 [00:03<00:07,  9.31it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  36%|\u001b[38;2;243;156;18m█████████▋                 \u001b[0m| 36/100 [00:04<00:06,  9.48it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  41%|\u001b[38;2;243;156;18m███████████                \u001b[0m| 41/100 [00:04<00:06,  9.59it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  46%|\u001b[38;2;243;156;18m████████████▍              \u001b[0m| 46/100 [00:05<00:05,  9.67it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  51%|\u001b[38;2;243;156;18m█████████████▊             \u001b[0m| 51/100 [00:05<00:05,  9.73it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  56%|\u001b[38;2;243;156;18m███████████████            \u001b[0m| 56/100 [00:06<00:04,  9.76it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  61%|\u001b[38;2;243;156;18m████████████████▍          \u001b[0m| 61/100 [00:06<00:03,  9.79it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  66%|\u001b[38;2;243;156;18m█████████████████▊         \u001b[0m| 66/100 [00:07<00:03,  9.80it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  71%|\u001b[38;2;243;156;18m███████████████████▏       \u001b[0m| 71/100 [00:07<00:02,  9.82it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  76%|\u001b[38;2;243;156;18m████████████████████▌      \u001b[0m| 76/100 [00:08<00:02,  9.83it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  81%|\u001b[38;2;243;156;18m█████████████████████▊     \u001b[0m| 81/100 [00:08<00:01,  9.84it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  86%|\u001b[38;2;243;156;18m███████████████████████▏   \u001b[0m| 86/100 [00:09<00:01,  9.83it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  91%|\u001b[38;2;243;156;18m████████████████████████▌  \u001b[0m| 91/100 [00:09<00:00,  9.84it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  96%|\u001b[38;2;243;156;18m█████████████████████████▉ \u001b[0m| 96/100 [00:10<00:00,  9.84it/s]\u001b[0m\u001b[A\n",
      "test:  75%|█████████████████████████████▎         | 3/4 [00:58<00:19, 19.02s/it]\u001b[A\n",
      "DDIM Sampling:   0%|\u001b[38;2;243;156;18m                                    \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   1%|\u001b[38;2;243;156;18m▎                           \u001b[0m| 1/100 [00:00<01:19,  1.24it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:   6%|\u001b[38;2;243;156;18m█▋                          \u001b[0m| 6/100 [00:01<00:17,  5.32it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  11%|\u001b[38;2;243;156;18m██▉                        \u001b[0m| 11/100 [00:01<00:12,  7.16it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  16%|\u001b[38;2;243;156;18m████▎                      \u001b[0m| 16/100 [00:02<00:10,  8.15it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  21%|\u001b[38;2;243;156;18m█████▋                     \u001b[0m| 21/100 [00:02<00:09,  8.74it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  26%|\u001b[38;2;243;156;18m███████                    \u001b[0m| 26/100 [00:03<00:08,  9.11it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  31%|\u001b[38;2;243;156;18m████████▎                  \u001b[0m| 31/100 [00:03<00:07,  9.35it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  36%|\u001b[38;2;243;156;18m█████████▋                 \u001b[0m| 36/100 [00:04<00:06,  9.51it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  41%|\u001b[38;2;243;156;18m███████████                \u001b[0m| 41/100 [00:04<00:06,  9.62it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  46%|\u001b[38;2;243;156;18m████████████▍              \u001b[0m| 46/100 [00:05<00:05,  9.69it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  51%|\u001b[38;2;243;156;18m█████████████▊             \u001b[0m| 51/100 [00:05<00:05,  9.74it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  56%|\u001b[38;2;243;156;18m███████████████            \u001b[0m| 56/100 [00:06<00:04,  9.78it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  61%|\u001b[38;2;243;156;18m████████████████▍          \u001b[0m| 61/100 [00:06<00:03,  9.81it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  66%|\u001b[38;2;243;156;18m█████████████████▊         \u001b[0m| 66/100 [00:07<00:03,  9.82it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  71%|\u001b[38;2;243;156;18m███████████████████▏       \u001b[0m| 71/100 [00:07<00:02,  9.84it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  76%|\u001b[38;2;243;156;18m████████████████████▌      \u001b[0m| 76/100 [00:08<00:02,  9.84it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  81%|\u001b[38;2;243;156;18m█████████████████████▊     \u001b[0m| 81/100 [00:08<00:01,  9.85it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  86%|\u001b[38;2;243;156;18m███████████████████████▏   \u001b[0m| 86/100 [00:09<00:01,  9.85it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  91%|\u001b[38;2;243;156;18m████████████████████████▌  \u001b[0m| 91/100 [00:09<00:00,  9.85it/s]\u001b[0m\u001b[A\n",
      "DDIM Sampling:  96%|\u001b[38;2;243;156;18m█████████████████████████▉ \u001b[0m| 96/100 [00:10<00:00,  9.86it/s]\u001b[0m\u001b[A\n",
      "test: 100%|███████████████████████████████████████| 4/4 [01:16<00:00, 19.24s/it]\u001b[A\n",
      "    test_TEST_FID  : 123.44289959495909\n"
     ]
    }
   ],
   "source": [
    "!python3 inference.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
